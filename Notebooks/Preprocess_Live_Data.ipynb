{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocess_Live_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfS8gr9UrATN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58633ab7-df70-4e3d-994a-7e5f7c9e6452"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG5TpVaurL9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e16725-e33a-48b9-acfb-96239da4fc59"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTGAyMnNrN3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416bf91f-650d-414f-f909-847ba8f9c90e"
      },
      "source": [
        "cd '/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG/Data/WALG_inference'"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG/Data/WALG_inference\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8HaQbBCEzM-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycF1FXSsbXQA"
      },
      "source": [
        "## Function to generate sliding windows.\n",
        "def sliding_window(frame_length, step, X, Y):\n",
        "  X_f = []\n",
        "  Y_f = []\n",
        "  for loop in range(0,X.shape[0]-frame_length,step):\n",
        "    # X_f.append(X[loop: loop+frame_length]);\n",
        "    X_f.append(\n",
        "      np.vstack((\n",
        "        X[loop: loop+frame_length],\n",
        "        np.mean(X[loop: loop+frame_length], axis=0),\n",
        "        np.std(X[loop: loop+frame_length], axis=0, dtype=np.float64)\n",
        "      ))\n",
        "    );\n",
        "    Y_f.append(Y[loop]);\n",
        "  return X_f, Y_f\n",
        "\n",
        "## Function to store data as numpy files.\n",
        "def numpify_and_store(X, y, X_name, y_name, outdatapath, shuffle=False):\n",
        "      X = np.array(X)\n",
        "      y = np.array(y)\n",
        "      # Shuffle the train set\n",
        "      if shuffle is True:\n",
        "          np.random.seed(123)\n",
        "          neworder = np.random.permutation(X.shape[0])\n",
        "          X = X[neworder, :, :]\n",
        "          y = y[neworder]\n",
        "      # Save binary file\n",
        "      xpath = os.path.join(outdatapath, X_name)\n",
        "      ypath = os.path.join(outdatapath, y_name)\n",
        "      np.save(xpath, X)\n",
        "      np.save(ypath, y)\n",
        "      print('Storing ' + xpath, ypath)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6fY_lNl5rfh"
      },
      "source": [
        "# Variables\n",
        "frame_length  = int(200);\n",
        "step          = 40;\n",
        "\n",
        "csv_file_list = [\n",
        "  '2020_11_22_Rahul_0_1', '2020_11_22_Mohit_0_1',\n",
        "  '2020_11_22_Mohit_2_1',\n",
        "  '2020_11_22_Rahul_3', '2020_11_21_Rahul_3', '2020_11_23_Rahul_3', '2020_11_24_Rahul_3', '2020_11_26_Rahul_3', '2020_11_29_Mohit_3',\n",
        "  '2020_11_20_Rahul_4', '2020_11_29_Mohit_4',\n",
        "  '2020_11_22_Rahul_1_1', '2020_11_22_Mohit_1_1', '2020_11_22_Rahul_1_2', '2020_11_22_Mohit_1_2',\n",
        "  '2020_12_04_Mohit_up_1', '2020_12_04_Mohit_down_1', '2020_12_04_Rahul_up_1', '2020_12_04_Rahul_down_1',\n",
        "  '2020_12_04_Mohit_5',\n",
        "  '2020_11_30_Rahul_5'\n",
        "];\n",
        "exp_activities = [0,0,2,3,3,3,3,3,3,4,4,1,1,1,1,1,1,1,1,5,6];\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hHMNiPaay7F",
        "outputId": "8614cdf4-9420-4aaa-b5c3-6c6c0ce72dac"
      },
      "source": [
        "for file_name in csv_file_list:\n",
        "  file_path = file_name+'.csv'\n",
        "  raw_data = pd.read_csv(file_path)\n",
        "  start_time = raw_data.iloc[0,0]\n",
        "  start_time = start_time.split()\n",
        "  end_time = raw_data.iloc[-1,0]\n",
        "  end_time = end_time.split(' ')\n",
        "  if (np.shape(start_time)[0] == 1 or np.shape(end_time)[0] == 1 ):\n",
        "    print ('Can\\'t extract time from the csv file: ' + file_name);\n",
        "  else:\n",
        "    date_time = pd.DataFrame({\n",
        "      'Date' : [start_time[0], end_time[0]],\n",
        "      'Time' : [start_time[1], end_time[1]]\n",
        "    })\n",
        "    date_time.to_csv(file_name+'_dt.csv')\n",
        "  formatted_data = pd.DataFrame(\n",
        "      {\n",
        "          \"acc_x\":   raw_data.loc[:,'accelerometerAccelerationX(G)'],\n",
        "          \"acc_y\":   raw_data.loc[:,'accelerometerAccelerationY(G)'],\n",
        "          \"acc_z\":   raw_data.loc[:,'accelerometerAccelerationZ(G)'],\n",
        "          \"gyro_x\":  raw_data.loc[:,'motionRotationRateX(rad/s)'],\n",
        "          \"gyro_y\":  raw_data.loc[:,'motionRotationRateY(rad/s)'],\n",
        "          \"gyro_z\":  raw_data.loc[:,'motionRotationRateZ(rad/s)'],\n",
        "          \"label\":   raw_data.loc[:,'label']\n",
        "      }\n",
        "  )\n",
        "  x_np = formatted_data.iloc[:,0:formatted_data.shape[1]-1].to_numpy();\n",
        "  y_np = formatted_data['label'].to_numpy();\n",
        "  x_psw_np, y_psw_np = sliding_window(frame_length, step, x_np, y_np);\n",
        "  numpify_and_store(\n",
        "    x_psw_np, \n",
        "    y_psw_np, \n",
        "    X_name='X_'+file_name, \n",
        "    y_name='Y_'+file_name, \n",
        "    outdatapath='./', \n",
        "    shuffle=True \n",
        "  );"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Storing ./X_2020_11_22_Rahul_0_1 ./Y_2020_11_22_Rahul_0_1\n",
            "Storing ./X_2020_11_22_Mohit_0_1 ./Y_2020_11_22_Mohit_0_1\n",
            "Storing ./X_2020_11_22_Mohit_2_1 ./Y_2020_11_22_Mohit_2_1\n",
            "Storing ./X_2020_11_22_Rahul_3 ./Y_2020_11_22_Rahul_3\n",
            "Can't extract time from the csv file: 2020_11_21_Rahul_3\n",
            "Storing ./X_2020_11_21_Rahul_3 ./Y_2020_11_21_Rahul_3\n",
            "Storing ./X_2020_11_23_Rahul_3 ./Y_2020_11_23_Rahul_3\n",
            "Storing ./X_2020_11_24_Rahul_3 ./Y_2020_11_24_Rahul_3\n",
            "Storing ./X_2020_11_26_Rahul_3 ./Y_2020_11_26_Rahul_3\n",
            "Storing ./X_2020_11_29_Mohit_3 ./Y_2020_11_29_Mohit_3\n",
            "Can't extract time from the csv file: 2020_11_20_Rahul_4\n",
            "Storing ./X_2020_11_20_Rahul_4 ./Y_2020_11_20_Rahul_4\n",
            "Storing ./X_2020_11_29_Mohit_4 ./Y_2020_11_29_Mohit_4\n",
            "Storing ./X_2020_11_22_Rahul_1_1 ./Y_2020_11_22_Rahul_1_1\n",
            "Storing ./X_2020_11_22_Mohit_1_1 ./Y_2020_11_22_Mohit_1_1\n",
            "Storing ./X_2020_11_22_Rahul_1_2 ./Y_2020_11_22_Rahul_1_2\n",
            "Storing ./X_2020_11_22_Mohit_1_2 ./Y_2020_11_22_Mohit_1_2\n",
            "Storing ./X_2020_12_04_Mohit_up_1 ./Y_2020_12_04_Mohit_up_1\n",
            "Storing ./X_2020_12_04_Mohit_down_1 ./Y_2020_12_04_Mohit_down_1\n",
            "Storing ./X_2020_12_04_Rahul_up_1 ./Y_2020_12_04_Rahul_up_1\n",
            "Storing ./X_2020_12_04_Rahul_down_1 ./Y_2020_12_04_Rahul_down_1\n",
            "Storing ./X_2020_12_04_Mohit_5 ./Y_2020_12_04_Mohit_5\n",
            "Can't extract time from the csv file: 2020_11_30_Rahul_5\n",
            "Storing ./X_2020_11_30_Rahul_5 ./Y_2020_11_30_Rahul_5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}