{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocess_Live_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfS8gr9UrATN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a99a7a-6445-4ec1-aec1-c1aed92e46f5"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG5TpVaurL9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be965f9-0070-495b-aebd-9f3adc4a222f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTGAyMnNrN3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad22da7d-d52f-470d-8ce0-ed0387e50924"
      },
      "source": [
        "cd '/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG/Data/Live_Data'"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG/Data/Live_Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8HaQbBCEzM-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycF1FXSsbXQA"
      },
      "source": [
        "## Function to generate sliding windows.\n",
        "def sliding_window(frame_length, step, X, Y, tstamps_all):\n",
        "  X_f = []\n",
        "  Y_f = []\n",
        "  tstamp = []\n",
        "  for loop in range(0,X.shape[0]-frame_length,step):\n",
        "    # X_f.append(X[loop: loop+frame_length]);\n",
        "    tstamp.append(tstamps_all[loop])\n",
        "    X_f.append(\n",
        "      np.vstack((\n",
        "        X[loop: loop+frame_length],\n",
        "        np.mean(X[loop: loop+frame_length], axis=0),\n",
        "        np.std(X[loop: loop+frame_length], axis=0, dtype=np.float64)\n",
        "      ))\n",
        "    );\n",
        "    Y_f.append(Y[loop]);\n",
        "  return X_f, Y_f, tstamp\n",
        "\n",
        "## Function to store data as numpy files.\n",
        "def numpify_and_store(X, y, X_name, y_name, outdatapath, shuffle=False):\n",
        "      X = np.array(X)\n",
        "      y = np.array(y)\n",
        "      # Shuffle the train set\n",
        "      if shuffle is True:\n",
        "          np.random.seed(123)\n",
        "          neworder = np.random.permutation(X.shape[0])\n",
        "          X = X[neworder, :, :]\n",
        "          y = y[neworder]\n",
        "      # Save binary file\n",
        "      xpath = os.path.join(outdatapath, X_name)\n",
        "      ypath = os.path.join(outdatapath, y_name)\n",
        "      np.save(xpath, X)\n",
        "      np.save(ypath, y)\n",
        "      print('Storing ' + xpath, ypath)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6fY_lNl5rfh"
      },
      "source": [
        "# Variables\n",
        "frame_length  = int(200);\n",
        "step          = 40;\n",
        "\n",
        "csv_file_list = [\n",
        "  '2020_11_22_Rahul_0_1', '2020_11_22_Mohit_0_1',\n",
        "  '2020_11_22_Mohit_2_1', '2020_12_16_Rahul_2',\n",
        "  '2020_11_22_Rahul_3', '2020_11_21_Rahul_3', '2020_11_23_Rahul_3', '2020_11_24_Rahul_3', '2020_11_26_Rahul_3', '2020_11_29_Mohit_3',\n",
        "  '2020_11_20_Rahul_4', '2020_11_29_Mohit_4'\n",
        "];\n",
        "exp_activities = [0,0,2,2,3,3,3,3,3,3,4,4];\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hHMNiPaay7F",
        "outputId": "24c25d5b-e60e-447f-8d21-c837b91eed59"
      },
      "source": [
        "for file_name in csv_file_list:\n",
        "  file_path = './raw/'+file_name+'.csv'\n",
        "  raw_data = pd.read_csv(file_path)\n",
        "  start_time = raw_data.iloc[0,0]\n",
        "  start_time = start_time.split()\n",
        "  end_time = raw_data.iloc[-1,0]\n",
        "  end_time = end_time.split(' ')\n",
        "  if (np.shape(start_time)[0] == 1 or np.shape(end_time)[0] == 1 ):\n",
        "    print ('Can\\'t extract time from the csv file: ' + file_name);\n",
        "  else:\n",
        "    date_time = pd.DataFrame({\n",
        "      'Date' : [start_time[0], end_time[0]],\n",
        "      'Time' : [start_time[1], end_time[1]]\n",
        "    })\n",
        "    date_time.to_csv('./processed/'+file_name+'_dt.csv')\n",
        "  formatted_data = pd.DataFrame(\n",
        "      {\n",
        "          \"acc_x\":   raw_data.loc[:,'accelerometerAccelerationX(G)'],\n",
        "          \"acc_y\":   raw_data.loc[:,'accelerometerAccelerationY(G)'],\n",
        "          \"acc_z\":   raw_data.loc[:,'accelerometerAccelerationZ(G)'],\n",
        "          \"gyro_x\":  raw_data.loc[:,'motionRotationRateX(rad/s)'],\n",
        "          \"gyro_y\":  raw_data.loc[:,'motionRotationRateY(rad/s)'],\n",
        "          \"gyro_z\":  raw_data.loc[:,'motionRotationRateZ(rad/s)'],\n",
        "          \"label\":   raw_data.loc[:,'label']\n",
        "      }\n",
        "  )\n",
        "  tstamps_all = raw_data.loc[:,'loggingTime(txt)']\n",
        "  x_np = formatted_data.iloc[:,0:formatted_data.shape[1]-1].to_numpy();\n",
        "  y_np = formatted_data['label'].to_numpy();\n",
        "  x_psw_np, y_psw_np, tstamp = sliding_window(frame_length, step, x_np, y_np, tstamps_all);\n",
        "  numpify_and_store(\n",
        "    x_psw_np, \n",
        "    y_psw_np, \n",
        "    X_name='X_'+file_name, \n",
        "    y_name='Y_'+file_name, \n",
        "    outdatapath='./processed/', \n",
        "    shuffle=False \n",
        "  );\n",
        "  np.savetxt(\n",
        "      'tstamps/'+file_name+'_tstamp.csv',  \n",
        "      tstamp, \n",
        "      delimiter =\", \",\n",
        "      fmt = \"%s\"\n",
        "  );"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Storing ./processed/X_2020_11_22_Rahul_0_1 ./processed/Y_2020_11_22_Rahul_0_1\n",
            "Storing ./processed/X_2020_11_22_Mohit_0_1 ./processed/Y_2020_11_22_Mohit_0_1\n",
            "Storing ./processed/X_2020_11_22_Mohit_2_1 ./processed/Y_2020_11_22_Mohit_2_1\n",
            "Storing ./processed/X_2020_12_16_Rahul_2 ./processed/Y_2020_12_16_Rahul_2\n",
            "Storing ./processed/X_2020_11_22_Rahul_3 ./processed/Y_2020_11_22_Rahul_3\n",
            "Can't extract time from the csv file: 2020_11_21_Rahul_3\n",
            "Storing ./processed/X_2020_11_21_Rahul_3 ./processed/Y_2020_11_21_Rahul_3\n",
            "Storing ./processed/X_2020_11_23_Rahul_3 ./processed/Y_2020_11_23_Rahul_3\n",
            "Storing ./processed/X_2020_11_24_Rahul_3 ./processed/Y_2020_11_24_Rahul_3\n",
            "Storing ./processed/X_2020_11_26_Rahul_3 ./processed/Y_2020_11_26_Rahul_3\n",
            "Storing ./processed/X_2020_11_29_Mohit_3 ./processed/Y_2020_11_29_Mohit_3\n",
            "Can't extract time from the csv file: 2020_11_20_Rahul_4\n",
            "Storing ./processed/X_2020_11_20_Rahul_4 ./processed/Y_2020_11_20_Rahul_4\n",
            "Storing ./processed/X_2020_11_29_Mohit_4 ./processed/Y_2020_11_29_Mohit_4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}