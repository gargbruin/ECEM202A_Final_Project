{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Final_WALG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmk2Acbo7Cv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6233dd3-0197-4fb1-ab1f-dfe0f2909c38"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiu5FWot7Jwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f66b77-2e5c-4a11-ecd3-c946ab670c06"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ1iPzL4Wjj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7603a8c-2ea4-48d6-97d5-d73838dd6461"
      },
      "source": [
        "cd '/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG/'"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAAGu9xw-sK8"
      },
      "source": [
        "Create a new folder in your Drive. (I created a folder named HAR) Copy the data files and the 2 pyrhon files to that folder (utils.py and existing_models.py). Then change working directory to that folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZAUBPgd7Cv9"
      },
      "source": [
        "from collections import Counter\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization, Permute, Reshape"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3vPh-fYj9FY"
      },
      "source": [
        "## Function to get details of the dataset used for training.\n",
        "def get_details(name):\n",
        "    if (name == 'PAM2'):\n",
        "        num_classes = 12\n",
        "        sensors = ['acc', 'gyr', 'mag']\n",
        "        locations = ['wrist', 'ankle', 'chest']\n",
        "        label_names = ['Lying', 'Sitting', 'Standing', 'Walking',\n",
        "                       'Running', 'Cycling', 'Nordic_walking', 'Ascending_stairs',\n",
        "                       'Descending_stairs', 'Vacuum_cleaning', 'Ironing', 'Rope_jumping']\n",
        "        f_hz = 100\n",
        "        dimensions = ['sensor', 'location', 'frequency']\n",
        "        path = './Data/'+name+'_test';\n",
        "    elif (name == 'WISDM'):\n",
        "        num_classes = 18\n",
        "        sensors = ['acc', 'gyr']\n",
        "        locations = ['wrist']\n",
        "        label_names = ['Walking', 'Jogging', 'Stairs', 'Sitting', 'Standing', 'Typing',\n",
        "                        'Brushing Teeth', 'Eating Soups', 'Eating Chips', 'Eating Pasta',\n",
        "                        'Drinking from Cup', 'Eating Sandwich', 'Kicking Soccer Ball', 'Playing catch with Tennis Ball',\n",
        "                        'Dribbling', 'Writing', 'Clapping', 'Folding Clothes']\n",
        "        f_hz = 20\n",
        "        dimensions = ['sensor', 'location', 'frequency']\n",
        "        path = './Data/'+name+'/wisdm-dataset/processed';\n",
        "    elif (name == 'WISDM_PAMAP2'):\n",
        "        num_classes = 7\n",
        "        sensors = ['Accelerometer', 'Gyroscope']\n",
        "        locations = ['Wrist Watch']\n",
        "        label_names = ['Walking', 'Stairs', 'Sitting', 'Brushing Teeth', 'Eating', 'Jogging', 'Clapping']\n",
        "        f_hz = 20\n",
        "        dimensions = ['sensor', 'location', 'frequency']\n",
        "        path = './Data/'+name+'/';\n",
        "    else:\n",
        "        print(\"No such dataset\")\n",
        "\n",
        "    return num_classes, sensors, locations, label_names, f_hz, dimensions, path\n",
        "\n",
        "## FUnction to load dataset for training the models.\n",
        "def load_dataset(name, path, num_classes):\n",
        "    if (name == 'PAM2'):\n",
        "        X_train0 = np.load(os.path.join(path, 'X_train_{}.npy'.format(name)))\n",
        "        y_train_binary = np.load(os.path.join(\n",
        "            path, 'y_train_{}.npy'.format(name)))\n",
        "        X_val0 = np.load(os.path.join(path, 'X_val_{}.npy'.format(name)))\n",
        "        y_val_binary = np.load(os.path.join(path, 'y_val_{}.npy'.format(name)))\n",
        "        X_test0 = np.load(os.path.join(path, 'X_test_{}.npy'.format(name)))\n",
        "        y_test_binary = np.load(os.path.join(\n",
        "            path, 'y_test_{}.npy'.format(name)))\n",
        "    elif (name == 'WISDM'):\n",
        "        X_train0 = np.load(os.path.join(path, 'X_WISDM_train.npy'))\n",
        "        y_train_binary = np.load(os.path.join(path, 'Y_WISDM_train.npy'))\n",
        "        X_val0 = np.load(os.path.join(path, 'X_WISDM_val.npy'))\n",
        "        y_val_binary = np.load(os.path.join(path, 'Y_WISDM_val.npy'))\n",
        "        X_test0 = np.load(os.path.join(path, 'X_WISDM_test.npy'))\n",
        "        y_test_binary = np.load(os.path.join(path, 'Y_WISDM_test.npy'))\n",
        "    elif (name == 'WISDM_PAMAP2'):\n",
        "        X_train0 = np.load(os.path.join(path, 'X_WISDM_PAMAP2_train.npy'))\n",
        "        y_train_binary = np.load(os.path.join(path, 'Y_WISDM_PAMAP2_train.npy'))\n",
        "        X_val0 = np.load(os.path.join(path, 'X_WISDM_PAMAP2_val.npy'))\n",
        "        y_val_binary = np.load(os.path.join(path, 'Y_WISDM_PAMAP2_val.npy'))\n",
        "        X_test0 = np.load(os.path.join(path, 'X_WISDM_PAMAP2_test.npy'))\n",
        "        y_test_binary = np.load(os.path.join(path, 'Y_WISDM_PAMAP2_test.npy'))\n",
        "    else:\n",
        "        print(\"No such dataset\")\n",
        "\n",
        "    return X_train0, y_train_binary, X_val0, y_val_binary, X_test0, y_test_binary\n",
        "\n",
        "## Function to reshape data as required by the mnodel.\n",
        "def reshape_data(X_tr, X_va, X_tst, network_type):\n",
        "    _, win_len, dim = X_tr.shape\n",
        "\n",
        "    if network_type == 'CNN' or network_type == 'ConvLSTM':\n",
        "        # make it into (frame_number, dimension, window_size, channel=1) for convNet\n",
        "        X_tr = np.swapaxes(X_tr, 1, 2)\n",
        "        X_va = np.swapaxes(X_va, 1, 2)\n",
        "        X_tst = np.swapaxes(X_tst, 1, 2)\n",
        "\n",
        "        X_tr = np.reshape(X_tr, (-1, dim, win_len, 1))\n",
        "        X_va = np.reshape(X_va, (-1, dim, win_len, 1))\n",
        "        X_tst = np.reshape(X_tst, (-1, dim, win_len, 1))\n",
        "\n",
        "    elif network_type == 'MLP':\n",
        "        X_tr = np.reshape(X_tr, (-1, dim * win_len))\n",
        "        X_va = np.reshape(X_va, (-1, dim * win_len))\n",
        "        X_tst = np.reshape(X_tst, (-1, dim * win_len))\n",
        "\n",
        "    return X_tr, X_va, X_tst\n",
        "\n",
        "## Function to define CNN model.\n",
        "def model_CNN(dim, win_len, num_classes, num_feat_map=64, p=0., batchnorm=True, dropout=True):\n",
        "    model = Sequential(name='CNN')\n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 3),\n",
        "                     activation='relu',\n",
        "                     input_shape=(dim, win_len, 1),\n",
        "                     padding='same', name='Conv_1'))\n",
        "    if batchnorm:\n",
        "        model.add(BatchNormalization(name='Bn_1'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), name='Max_pool_1'))\n",
        "    if dropout:\n",
        "        model.add(Dropout(p, name='Drop_1'))\n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 3),\n",
        "                     activation='relu', padding='same', name='Conv_2'))\n",
        "    if batchnorm:\n",
        "        model.add(BatchNormalization(name='Bn_2'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), name='Max_pool_2'))\n",
        "    if dropout:\n",
        "        model.add(Dropout(p, name='Drop_2'))\n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 3),\n",
        "                     activation='relu', padding='same', name='Conv_3'))\n",
        "    if batchnorm:\n",
        "        model.add(BatchNormalization(name='Bn_3'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), name='Max_pool_3'))\n",
        "    if dropout:\n",
        "        model.add(Dropout(p, name='Drop_3'))\n",
        "    model.add(Flatten(name='Flatten_1'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    if batchnorm:\n",
        "        model.add(BatchNormalization(name='Bn_4'))\n",
        "    if dropout:\n",
        "        model.add(Dropout(p, name='Drop_4'))\n",
        "    model.add(Dense(num_classes, activation='softmax', name='dense_out'))\n",
        "    return model\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgTsD0dfl7m5"
      },
      "source": [
        "# Variables\n",
        "d_name        = 'WISDM_PAMAP2';\n",
        "network_type  = 'CNN';\n",
        "batch_size    = 256;\n",
        "epochs        = 50;\n",
        "model_dir     = f'Models/{d_name}';\n",
        "model_name    = '{}_{}'.format(network_type, int(time.time()));\n",
        "filepath      = f\"best_{model_name}.hdf5\";\n",
        "chk_path      = os.path.join(model_dir, filepath);\n",
        "\n",
        "ACTIVITIES_MAP = {\n",
        "    0: 'Walking',\n",
        "    1: 'Stairs',\n",
        "    2: 'Sitting',\n",
        "    3: 'Brushing Teeth',\n",
        "    4: 'Eating',\n",
        "    5: 'Jogging',\n",
        "    6: 'Clapping'\n",
        "}"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLQJCfAg7Cv_"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfX7wcH7Cv_"
      },
      "source": [
        "Load the preprocessed data as stored in Numpy-files. Please note that the data has already been split up in a training (training), validation (val), and test subsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tovCMtHC7CwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3b9d73-7647-480d-864a-5af4794aff0a"
      },
      "source": [
        "# Load the dataset for training\n",
        "num_classes, sensors, locations, label_names, f_hz, dimensions, path = get_details(d_name)\n",
        "print(\"Number of classes:  \", num_classes)\n",
        "print(\"Sensors:            \", sensors)\n",
        "print(\"Devices:            \",locations)\n",
        "print(\"Sampling frequency: \",f_hz)\n",
        "\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "X_train0, y_train_binary, X_val0, y_val_binary, X_test0, y_test_binary = load_dataset(d_name, path, num_classes)\n",
        "print (\"Dataset Shapes:\")\n",
        "print(\"  Train inputs:      \",X_train0.shape);\n",
        "print(\"  Test inputs:       \",X_test0.shape);\n",
        "print(\"  Validation inputs: \",X_val0.shape);\n",
        "print(\"  Train labels:      \", y_train_binary.shape);\n",
        "print(\"  Test labels:       \",y_test_binary.shape);\n",
        "print(\"  Validation labels: \",y_val_binary.shape);\n",
        "\n",
        "np.load = np_load_old\n",
        "\n",
        "# Counting data for different activities\n",
        "y_train = np.argmax(y_train_binary, axis=1)\n",
        "y_test = np.argmax(y_test_binary, axis=1)\n",
        "y_val = np.argmax(y_val_binary, axis=1)\n",
        "\n",
        "print (\"Amount of data for each activity: \");\n",
        "train_count = Counter(y_train);\n",
        "print(\" Training Data:\");\n",
        "for activity in ACTIVITIES_MAP.keys():\n",
        "  print (\"    {} = {}\".format(ACTIVITIES_MAP[activity], train_count[activity]));\n",
        "val_count = Counter(y_val);\n",
        "print(\" Validation Data:\");\n",
        "for activity in ACTIVITIES_MAP.keys():\n",
        "  print (\"    {} = {}\".format(ACTIVITIES_MAP[activity], val_count[activity]));\n",
        "test_count = Counter(y_test);\n",
        "print(\" Testing Data:\");\n",
        "for activity in ACTIVITIES_MAP.keys():\n",
        "  print (\"    {} = {}\".format(ACTIVITIES_MAP[activity], test_count[activity]));   \n",
        "\n",
        "# Converting all the data to float32.\n",
        "X_train0        = np.asarray(X_train0).astype('float32')\n",
        "X_test0         = np.asarray(X_test0).astype('float32')\n",
        "X_val0          = np.asarray(X_val0).astype('float32')\n",
        "y_train_binary  = np.asarray(y_train_binary).astype('float32')\n",
        "y_test_binary   = np.asarray(y_test_binary).astype('float32')\n",
        "y_val_binary    = np.asarray(y_val_binary).astype('float32')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of classes:   7\n",
            "Sensors:             ['Accelerometer', 'Gyroscope']\n",
            "Devices:             ['Wrist Watch']\n",
            "Sampling frequency:  20\n",
            "Dataset Shapes:\n",
            "  Train inputs:       (31045, 202, 6)\n",
            "  Test inputs:        (6469, 202, 6)\n",
            "  Validation inputs:  (4151, 202, 6)\n",
            "  Train labels:       (31045, 7)\n",
            "  Test labels:        (6469, 7)\n",
            "  Validation labels:  (4151, 7)\n",
            "Amount of data for each activity: \n",
            " Training Data:\n",
            "    Walking = 4095\n",
            "    Stairs = 3278\n",
            "    Sitting = 7252\n",
            "    Brushing Teeth = 3279\n",
            "    Eating = 6671\n",
            "    Jogging = 3191\n",
            "    Clapping = 3279\n",
            " Validation Data:\n",
            "    Walking = 582\n",
            "    Stairs = 362\n",
            "    Sitting = 917\n",
            "    Brushing Teeth = 474\n",
            "    Eating = 911\n",
            "    Jogging = 438\n",
            "    Clapping = 467\n",
            " Testing Data:\n",
            "    Walking = 841\n",
            "    Stairs = 737\n",
            "    Sitting = 1465\n",
            "    Brushing Teeth = 682\n",
            "    Eating = 1364\n",
            "    Jogging = 698\n",
            "    Clapping = 682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmrbY32o7CwH"
      },
      "source": [
        "## My Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MBfizq6l7CwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6ad60a-de8a-4453-f530-dd12809254dd"
      },
      "source": [
        "print('Reshaping data for different models ...')\n",
        "X_train, X_val, X_test = reshape_data(X_train0, X_val0, X_test0, network_type)\n",
        "_, win_len, dim = X_train0.shape\n",
        "\n",
        "print('Building the model ...')\n",
        "model = model_CNN(dim, win_len, num_classes, num_feat_map=64, p=0.3)\n",
        "print(model.summary())\n",
        "\n",
        "print('Training the model ...')\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir = os.path.join('logs', '{}'.format(model_name)))\n",
        "\n",
        "checkpoint = ModelCheckpoint(chk_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit(X_train, y_train_binary,\n",
        "          batch_size=300,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          shuffle=True,\n",
        "          validation_data=(X_val, y_val_binary),\n",
        "          callbacks=[tensorboard, checkpoint])\n",
        "\n",
        "model.save(os.path.join(model_dir,f'final_{model_name}.hdf5'))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reshaping data for different models ...\n",
            "Building the model ...\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv_1 (Conv2D)              (None, 6, 202, 64)        256       \n",
            "_________________________________________________________________\n",
            "Bn_1 (BatchNormalization)    (None, 6, 202, 64)        256       \n",
            "_________________________________________________________________\n",
            "Max_pool_1 (MaxPooling2D)    (None, 6, 101, 64)        0         \n",
            "_________________________________________________________________\n",
            "Drop_1 (Dropout)             (None, 6, 101, 64)        0         \n",
            "_________________________________________________________________\n",
            "Conv_2 (Conv2D)              (None, 6, 101, 64)        12352     \n",
            "_________________________________________________________________\n",
            "Bn_2 (BatchNormalization)    (None, 6, 101, 64)        256       \n",
            "_________________________________________________________________\n",
            "Max_pool_2 (MaxPooling2D)    (None, 6, 50, 64)         0         \n",
            "_________________________________________________________________\n",
            "Drop_2 (Dropout)             (None, 6, 50, 64)         0         \n",
            "_________________________________________________________________\n",
            "Conv_3 (Conv2D)              (None, 6, 50, 64)         12352     \n",
            "_________________________________________________________________\n",
            "Bn_3 (BatchNormalization)    (None, 6, 50, 64)         256       \n",
            "_________________________________________________________________\n",
            "Max_pool_3 (MaxPooling2D)    (None, 6, 25, 64)         0         \n",
            "_________________________________________________________________\n",
            "Drop_3 (Dropout)             (None, 6, 25, 64)         0         \n",
            "_________________________________________________________________\n",
            "Flatten_1 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                307232    \n",
            "_________________________________________________________________\n",
            "Bn_4 (BatchNormalization)    (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "Drop_4 (Dropout)             (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_out (Dense)            (None, 7)                 231       \n",
            "=================================================================\n",
            "Total params: 333,319\n",
            "Trainable params: 332,871\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training the model ...\n",
            "Epoch 1/50\n",
            "  2/104 [..............................] - ETA: 9s - loss: 2.2373 - accuracy: 0.2867WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0210s vs `on_train_batch_end` time: 0.1430s). Check your callbacks.\n",
            "102/104 [============================>.] - ETA: 0s - loss: 0.5429 - accuracy: 0.8046\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.36377, saving model to Models/WISDM_PAMAP2/best_CNN_1607824644.hdf5\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 0.5403 - accuracy: 0.8057 - val_loss: 1.6634 - val_accuracy: 0.3638\n",
            "Epoch 2/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.9068\n",
            "Epoch 00002: val_accuracy improved from 0.36377 to 0.55095, saving model to Models/WISDM_PAMAP2/best_CNN_1607824644.hdf5\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.2894 - accuracy: 0.9067 - val_loss: 1.3706 - val_accuracy: 0.5510\n",
            "Epoch 3/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9251\n",
            "Epoch 00003: val_accuracy improved from 0.55095 to 0.65093, saving model to Models/WISDM_PAMAP2/best_CNN_1607824644.hdf5\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.2318 - accuracy: 0.9253 - val_loss: 1.1113 - val_accuracy: 0.6509\n",
            "Epoch 4/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9335\n",
            "Epoch 00004: val_accuracy improved from 0.65093 to 0.77716, saving model to Models/WISDM_PAMAP2/best_CNN_1607824644.hdf5\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.1972 - accuracy: 0.9335 - val_loss: 0.8087 - val_accuracy: 0.7772\n",
            "Epoch 5/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9420\n",
            "Epoch 00005: val_accuracy did not improve from 0.77716\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.1702 - accuracy: 0.9421 - val_loss: 0.8300 - val_accuracy: 0.7634\n",
            "Epoch 6/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.9536\n",
            "Epoch 00006: val_accuracy did not improve from 0.77716\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.1455 - accuracy: 0.9535 - val_loss: 0.8913 - val_accuracy: 0.7523\n",
            "Epoch 7/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9555\n",
            "Epoch 00007: val_accuracy did not improve from 0.77716\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.1329 - accuracy: 0.9554 - val_loss: 0.9391 - val_accuracy: 0.7350\n",
            "Epoch 8/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1202 - accuracy: 0.9609\n",
            "Epoch 00008: val_accuracy did not improve from 0.77716\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.1200 - accuracy: 0.9609 - val_loss: 1.0332 - val_accuracy: 0.7697\n",
            "Epoch 9/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1103 - accuracy: 0.9645\n",
            "Epoch 00009: val_accuracy did not improve from 0.77716\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.1101 - accuracy: 0.9646 - val_loss: 1.0464 - val_accuracy: 0.7408\n",
            "Epoch 10/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.9651\n",
            "Epoch 00010: val_accuracy did not improve from 0.77716\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.1042 - accuracy: 0.9651 - val_loss: 0.9939 - val_accuracy: 0.7654\n",
            "Epoch 11/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9691\n",
            "Epoch 00011: val_accuracy did not improve from 0.77716\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0957 - accuracy: 0.9690 - val_loss: 0.9993 - val_accuracy: 0.7726\n",
            "Epoch 12/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 0.9718\n",
            "Epoch 00012: val_accuracy improved from 0.77716 to 0.79475, saving model to Models/WISDM_PAMAP2/best_CNN_1607824644.hdf5\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 0.0847 - accuracy: 0.9718 - val_loss: 0.9139 - val_accuracy: 0.7947\n",
            "Epoch 13/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9726\n",
            "Epoch 00013: val_accuracy did not improve from 0.79475\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0827 - accuracy: 0.9727 - val_loss: 1.0213 - val_accuracy: 0.7779\n",
            "Epoch 14/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 0.9745\n",
            "Epoch 00014: val_accuracy did not improve from 0.79475\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0742 - accuracy: 0.9746 - val_loss: 1.0231 - val_accuracy: 0.7738\n",
            "Epoch 15/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 0.9757\n",
            "Epoch 00015: val_accuracy did not improve from 0.79475\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0727 - accuracy: 0.9756 - val_loss: 1.1055 - val_accuracy: 0.7839\n",
            "Epoch 16/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9771\n",
            "Epoch 00016: val_accuracy did not improve from 0.79475\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0681 - accuracy: 0.9771 - val_loss: 1.1546 - val_accuracy: 0.7810\n",
            "Epoch 17/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9773\n",
            "Epoch 00017: val_accuracy did not improve from 0.79475\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0662 - accuracy: 0.9774 - val_loss: 1.0861 - val_accuracy: 0.7805\n",
            "Epoch 18/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9774\n",
            "Epoch 00018: val_accuracy did not improve from 0.79475\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0648 - accuracy: 0.9775 - val_loss: 1.2087 - val_accuracy: 0.7781\n",
            "Epoch 19/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9817\n",
            "Epoch 00019: val_accuracy did not improve from 0.79475\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0556 - accuracy: 0.9817 - val_loss: 1.1225 - val_accuracy: 0.7523\n",
            "Epoch 20/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9819\n",
            "Epoch 00020: val_accuracy did not improve from 0.79475\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0553 - accuracy: 0.9819 - val_loss: 1.2797 - val_accuracy: 0.7805\n",
            "Epoch 21/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 0.9829\n",
            "Epoch 00021: val_accuracy improved from 0.79475 to 0.79499, saving model to Models/WISDM_PAMAP2/best_CNN_1607824644.hdf5\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 0.0504 - accuracy: 0.9829 - val_loss: 1.1162 - val_accuracy: 0.7950\n",
            "Epoch 22/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9839\n",
            "Epoch 00022: val_accuracy improved from 0.79499 to 0.79643, saving model to Models/WISDM_PAMAP2/best_CNN_1607824644.hdf5\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0465 - accuracy: 0.9838 - val_loss: 1.3060 - val_accuracy: 0.7964\n",
            "Epoch 23/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9841\n",
            "Epoch 00023: val_accuracy did not improve from 0.79643\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0462 - accuracy: 0.9840 - val_loss: 1.2092 - val_accuracy: 0.7960\n",
            "Epoch 24/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9841\n",
            "Epoch 00024: val_accuracy did not improve from 0.79643\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0483 - accuracy: 0.9841 - val_loss: 1.3085 - val_accuracy: 0.7654\n",
            "Epoch 25/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9856\n",
            "Epoch 00025: val_accuracy did not improve from 0.79643\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0431 - accuracy: 0.9856 - val_loss: 1.5568 - val_accuracy: 0.7803\n",
            "Epoch 26/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9840\n",
            "Epoch 00026: val_accuracy improved from 0.79643 to 0.79981, saving model to Models/WISDM_PAMAP2/best_CNN_1607824644.hdf5\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 0.0471 - accuracy: 0.9840 - val_loss: 1.2531 - val_accuracy: 0.7998\n",
            "Epoch 27/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.9861\n",
            "Epoch 00027: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0409 - accuracy: 0.9861 - val_loss: 1.2694 - val_accuracy: 0.7721\n",
            "Epoch 28/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.9861\n",
            "Epoch 00028: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 1.3854 - val_accuracy: 0.7533\n",
            "Epoch 29/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9861\n",
            "Epoch 00029: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 1.3082 - val_accuracy: 0.7707\n",
            "Epoch 30/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9870\n",
            "Epoch 00030: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 1.2912 - val_accuracy: 0.7786\n",
            "Epoch 31/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9865\n",
            "Epoch 00031: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0379 - accuracy: 0.9865 - val_loss: 1.5340 - val_accuracy: 0.7933\n",
            "Epoch 32/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9882\n",
            "Epoch 00032: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0342 - accuracy: 0.9881 - val_loss: 1.4193 - val_accuracy: 0.7858\n",
            "Epoch 33/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9878\n",
            "Epoch 00033: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 1.3921 - val_accuracy: 0.7950\n",
            "Epoch 34/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9882\n",
            "Epoch 00034: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0359 - accuracy: 0.9881 - val_loss: 1.4336 - val_accuracy: 0.7738\n",
            "Epoch 35/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9882\n",
            "Epoch 00035: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 1.5342 - val_accuracy: 0.7868\n",
            "Epoch 36/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9871\n",
            "Epoch 00036: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0361 - accuracy: 0.9871 - val_loss: 1.4089 - val_accuracy: 0.7796\n",
            "Epoch 37/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9881\n",
            "Epoch 00037: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0324 - accuracy: 0.9880 - val_loss: 1.4542 - val_accuracy: 0.7993\n",
            "Epoch 38/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9894\n",
            "Epoch 00038: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0322 - accuracy: 0.9894 - val_loss: 1.4788 - val_accuracy: 0.7868\n",
            "Epoch 39/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9884\n",
            "Epoch 00039: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 1.4257 - val_accuracy: 0.7923\n",
            "Epoch 40/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9896\n",
            "Epoch 00040: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 1.4310 - val_accuracy: 0.7697\n",
            "Epoch 41/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9901\n",
            "Epoch 00041: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0296 - accuracy: 0.9901 - val_loss: 1.4829 - val_accuracy: 0.7899\n",
            "Epoch 42/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9915\n",
            "Epoch 00042: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 1.5546 - val_accuracy: 0.7813\n",
            "Epoch 43/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9912\n",
            "Epoch 00043: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 1.5398 - val_accuracy: 0.7832\n",
            "Epoch 44/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9920\n",
            "Epoch 00044: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 1.4338 - val_accuracy: 0.7685\n",
            "Epoch 45/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9906\n",
            "Epoch 00045: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 1.5032 - val_accuracy: 0.7762\n",
            "Epoch 46/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9899\n",
            "Epoch 00046: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0280 - accuracy: 0.9899 - val_loss: 1.5604 - val_accuracy: 0.7798\n",
            "Epoch 47/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9902\n",
            "Epoch 00047: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 1.6022 - val_accuracy: 0.7870\n",
            "Epoch 48/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9906\n",
            "Epoch 00048: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 1.6401 - val_accuracy: 0.7904\n",
            "Epoch 49/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9915\n",
            "Epoch 00049: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 1.5640 - val_accuracy: 0.7858\n",
            "Epoch 50/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9904\n",
            "Epoch 00050: val_accuracy did not improve from 0.79981\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0259 - accuracy: 0.9904 - val_loss: 1.4595 - val_accuracy: 0.7673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHzUiWAP7CwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "244f9e93-fb63-49d5-e715-df5b52569efc"
      },
      "source": [
        "## Reloading saved model\n",
        "print(\"Loading the model: {}\".format(chk_path));\n",
        "model = load_model(chk_path);"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the model: Models/WISDM_PAMAP2/best_CNN_1607824644.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SghxinCU7CwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085b7a56-69a0-4636-a96b-a3857a0e5e79"
      },
      "source": [
        "## Testing the trained model accuracy with test data set.\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test_binary, axis=1)\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix: \")\n",
        "print(cf_matrix)\n",
        "class_wise_f1 = f1_score(y_true, y_pred, average=None)\n",
        "print('The mean-f1 score: {:.4f}'.format(np.mean(class_wise_f1)))\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print('Accuracy is: {:.4f}'.format(accuracy))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            "[[ 639  163   14   12    5    8    0]\n",
            " [  62  627   10    1   32    5    0]\n",
            " [   0    0 1254    0  186    0   25]\n",
            " [   0    0    0  671   11    0    0]\n",
            " [   1    0  136    1 1207    0   19]\n",
            " [   6   13    0    0    4  675    0]\n",
            " [   0    0    0    4    0    0  678]]\n",
            "The mean-f1 score: 0.8984\n",
            "Accuracy is: 0.8890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6vIt869s9h4"
      },
      "source": [
        "Perform Inference on live data collected from Apple Watch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boWa5B_c2FCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9436fd-33f9-4140-df4d-1b7916b80a0e"
      },
      "source": [
        "# Live data collected from Apple Watch\n",
        "file_list = [\n",
        "  '2020_11_22_Rahul_0_1', '2020_11_22_Mohit_0_1',\n",
        "  '2020_11_22_Mohit_2_1',\n",
        "  '2020_11_22_Rahul_3', '2020_11_21_Rahul_3', '2020_11_23_Rahul_3', '2020_11_24_Rahul_3', '2020_11_26_Rahul_3', '2020_11_29_Mohit_3',\n",
        "  '2020_11_20_Rahul_4', '2020_11_29_Mohit_4',\n",
        "  '2020_11_22_Rahul_1_1', '2020_11_22_Mohit_1_1', '2020_11_22_Rahul_1_2', '2020_11_22_Mohit_1_2',\n",
        "  '2020_12_04_Mohit_up_1', '2020_12_04_Mohit_down_1', '2020_12_04_Rahul_up_1', '2020_12_04_Rahul_down_1',\n",
        "  '2020_12_04_Mohit_5',\n",
        "  '2020_11_30_Rahul_5'\n",
        "];\n",
        "exp_activities = [0,0,2,3,3,3,3,3,3,4,4,1,1,1,1,1,1,1,1,5,6];\n",
        "\n",
        "for (file_name,exp_act) in zip(file_list,exp_activities):\n",
        "  X_data0 = np.load('./Data/WALG_inference/X_'+file_name+'.npy')\n",
        "  Y_true = np.load('./Data/WALG_inference/Y_'+file_name+'.npy')\n",
        "\n",
        "  X_data, a, b = reshape_data(X_data0, X_data0, X_data0, network_type)\n",
        "  Y_pred = np.argmax(model.predict(X_data), axis=1)\n",
        "  cf_matrix = confusion_matrix(Y_true, Y_pred)\n",
        "  class_wise_f1 = f1_score(Y_true, Y_pred, average=None)\n",
        "  accuracy = accuracy_score(Y_true, Y_pred)\n",
        "  counts = np.bincount(Y_pred)\n",
        "  activity_id = np.argmax(counts)\n",
        "  print(\"===========================================================\");\n",
        "  if os.path.exists('./Data/WALG_inference/'+file_name+'_dt.csv'):\n",
        "    dt = pd.read_csv('./Data/WALG_inference/'+file_name+'_dt.csv');\n",
        "    print (\"Activity Start Time: \" + str(dt.iloc[0,1]) + ' ' +str(dt.iloc[0,2]) );\n",
        "    print (\"Activity End Time:   \" + str(dt.iloc[1,1]) + ' ' +str(dt.iloc[1,2]) );\n",
        "  print('Accuracy:            {:.4f}'.format(accuracy))\n",
        "  print(\"Expected Activity:   {}\".format(ACTIVITIES_MAP[exp_act]));    \n",
        "  print(\"Detected Activity:   {}\".format(ACTIVITIES_MAP[activity_id]));\n",
        "  print(\"===========================================================\");"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 10:49:11.637\n",
            "Activity End Time:   2020-11-22 10:59:22.238\n",
            "Accuracy:            0.9900\n",
            "Expected Activity:   Walking\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 11:25:36.540\n",
            "Activity End Time:   2020-11-22 11:32:01.269\n",
            "Accuracy:            0.9521\n",
            "Expected Activity:   Walking\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 12:25:24.437\n",
            "Activity End Time:   2020-11-22 12:27:07.375\n",
            "Accuracy:            0.8085\n",
            "Expected Activity:   Sitting\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 09:37:32.630\n",
            "Activity End Time:   2020-11-22 09:40:18.282\n",
            "Accuracy:            1.0000\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Accuracy:            1.0000\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-23 08:25:43.287\n",
            "Activity End Time:   2020-11-23 08:28:32.150\n",
            "Accuracy:            0.9875\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-24 09:28:23.732\n",
            "Activity End Time:   2020-11-24 09:30:49.135\n",
            "Accuracy:            0.9559\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-26 09:49:01.224\n",
            "Activity End Time:   2020-11-26 09:51:51.980\n",
            "Accuracy:            0.9753\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-29 18:37:20.689\n",
            "Activity End Time:   2020-11-29 18:39:38.849\n",
            "Accuracy:            0.8308\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Accuracy:            1.0000\n",
            "Expected Activity:   Eating\n",
            "Detected Activity:   Eating\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-29 18:45:56.215\n",
            "Activity End Time:   2020-11-29 18:50:37.730\n",
            "Accuracy:            0.8162\n",
            "Expected Activity:   Eating\n",
            "Detected Activity:   Eating\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 11:45:00.744\n",
            "Activity End Time:   2020-11-22 11:47:35.607\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 11:37:34.255\n",
            "Activity End Time:   2020-11-22 11:39:50.607\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 12:17:08.319\n",
            "Activity End Time:   2020-11-22 12:19:44.195\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 12:08:08.875\n",
            "Activity End Time:   2020-11-22 12:10:19.313\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:32:44.320\n",
            "Activity End Time:   2020-12-04 12:33:35.324\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:34:03.442\n",
            "Activity End Time:   2020-12-04 12:34:48.766\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:35:23.692\n",
            "Activity End Time:   2020-12-04 12:36:28.972\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:36:33.574\n",
            "Activity End Time:   2020-12-04 12:37:32.956\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:36:33.574\n",
            "Activity End Time:   2020-12-04 12:37:32.956\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Jogging\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Clapping\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A88qTryjyNTU"
      },
      "source": [
        ""
      ],
      "execution_count": 76,
      "outputs": []
    }
  ]
}