{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Final_WALG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmk2Acbo7Cv2"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiu5FWot7Jwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a3c873-397b-4079-8015-ae317f7ed382"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ1iPzL4Wjj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11db2547-88ae-4c97-b4ed-d4cd593da1e4"
      },
      "source": [
        "cd '/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAAGu9xw-sK8"
      },
      "source": [
        "Create a new folder in your Drive. (I created a folder named HAR) Copy the data files and the 2 pyrhon files to that folder (utils.py and existing_models.py). Then change working directory to that folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZAUBPgd7Cv9"
      },
      "source": [
        "from collections import Counter\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization, Permute, Reshape"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3vPh-fYj9FY"
      },
      "source": [
        "## Function to get details of the dataset used for training.\n",
        "def get_details(name):\n",
        "    if (name == 'PAM2'):\n",
        "        num_classes = 12\n",
        "        sensors = ['acc', 'gyr', 'mag']\n",
        "        locations = ['wrist', 'ankle', 'chest']\n",
        "        label_names = ['Lying', 'Sitting', 'Standing', 'Walking',\n",
        "                       'Running', 'Cycling', 'Nordic_walking', 'Ascending_stairs',\n",
        "                       'Descending_stairs', 'Vacuum_cleaning', 'Ironing', 'Rope_jumping']\n",
        "        f_hz = 100\n",
        "        dimensions = ['sensor', 'location', 'frequency']\n",
        "        path = './Data/'+name+'_test';\n",
        "    elif (name == 'WISDM'):\n",
        "        num_classes = 18\n",
        "        sensors = ['acc', 'gyr']\n",
        "        locations = ['wrist']\n",
        "        label_names = ['Walking', 'Jogging', 'Stairs', 'Sitting', 'Standing', 'Typing',\n",
        "                        'Brushing Teeth', 'Eating Soups', 'Eating Chips', 'Eating Pasta',\n",
        "                        'Drinking from Cup', 'Eating Sandwich', 'Kicking Soccer Ball', 'Playing catch with Tennis Ball',\n",
        "                        'Dribbling', 'Writing', 'Clapping', 'Folding Clothes']\n",
        "        f_hz = 20\n",
        "        dimensions = ['sensor', 'location', 'frequency']\n",
        "        path = './Data/'+name+'/wisdm-dataset/processed';\n",
        "    elif (name == 'WISDM_PAMAP2'):\n",
        "        num_classes = 7\n",
        "        sensors = ['Accelerometer', 'Gyroscope']\n",
        "        locations = ['Wrist Watch']\n",
        "        label_names = ['Walking', 'Stairs', 'Sitting', 'Brushing Teeth', 'Eating', 'Jogging', 'Clapping']\n",
        "        f_hz = 20\n",
        "        dimensions = ['sensor', 'location', 'frequency']\n",
        "        path = './Data/'+name+'/';\n",
        "    else:\n",
        "        print(\"No such dataset\")\n",
        "\n",
        "    return num_classes, sensors, locations, label_names, f_hz, dimensions, path\n",
        "\n",
        "## FUnction to load dataset for training the models.\n",
        "def load_dataset(name, path, num_classes):\n",
        "    if (name == 'PAM2'):\n",
        "        X_train0 = np.load(os.path.join(path, 'X_train_{}.npy'.format(name)))\n",
        "        y_train_binary = np.load(os.path.join(\n",
        "            path, 'y_train_{}.npy'.format(name)))\n",
        "        X_val0 = np.load(os.path.join(path, 'X_val_{}.npy'.format(name)))\n",
        "        y_val_binary = np.load(os.path.join(path, 'y_val_{}.npy'.format(name)))\n",
        "        X_test0 = np.load(os.path.join(path, 'X_test_{}.npy'.format(name)))\n",
        "        y_test_binary = np.load(os.path.join(\n",
        "            path, 'y_test_{}.npy'.format(name)))\n",
        "    elif (name == 'WISDM'):\n",
        "        X_train0 = np.load(os.path.join(path, 'X_WISDM_train.npy'))\n",
        "        y_train_binary = np.load(os.path.join(path, 'Y_WISDM_train.npy'))\n",
        "        X_val0 = np.load(os.path.join(path, 'X_WISDM_val.npy'))\n",
        "        y_val_binary = np.load(os.path.join(path, 'Y_WISDM_val.npy'))\n",
        "        X_test0 = np.load(os.path.join(path, 'X_WISDM_test.npy'))\n",
        "        y_test_binary = np.load(os.path.join(path, 'Y_WISDM_test.npy'))\n",
        "    elif (name == 'WISDM_PAMAP2'):\n",
        "        X_train0 = np.load(os.path.join(path, 'X_WISDM_PAMAP2_train.npy'))\n",
        "        y_train_binary = np.load(os.path.join(path, 'Y_WISDM_PAMAP2_train.npy'))\n",
        "        X_val0 = np.load(os.path.join(path, 'X_WISDM_PAMAP2_val.npy'))\n",
        "        y_val_binary = np.load(os.path.join(path, 'Y_WISDM_PAMAP2_val.npy'))\n",
        "        X_test0 = np.load(os.path.join(path, 'X_WISDM_PAMAP2_test.npy'))\n",
        "        y_test_binary = np.load(os.path.join(path, 'Y_WISDM_PAMAP2_test.npy'))\n",
        "    else:\n",
        "        print(\"No such dataset\")\n",
        "\n",
        "    return X_train0, y_train_binary, X_val0, y_val_binary, X_test0, y_test_binary\n",
        "\n",
        "## Function to reshape data as required by the mnodel.\n",
        "def reshape_data(X_tr, X_va, X_tst, network_type):\n",
        "    _, win_len, dim = X_tr.shape\n",
        "\n",
        "    if network_type == 'CNN' or network_type == 'ConvLSTM':\n",
        "        # make it into (frame_number, dimension, window_size, channel=1) for convNet\n",
        "        X_tr = np.swapaxes(X_tr, 1, 2)\n",
        "        X_va = np.swapaxes(X_va, 1, 2)\n",
        "        X_tst = np.swapaxes(X_tst, 1, 2)\n",
        "\n",
        "        X_tr = np.reshape(X_tr, (-1, dim, win_len, 1))\n",
        "        X_va = np.reshape(X_va, (-1, dim, win_len, 1))\n",
        "        X_tst = np.reshape(X_tst, (-1, dim, win_len, 1))\n",
        "\n",
        "    elif network_type == 'MLP':\n",
        "        X_tr = np.reshape(X_tr, (-1, dim * win_len))\n",
        "        X_va = np.reshape(X_va, (-1, dim * win_len))\n",
        "        X_tst = np.reshape(X_tst, (-1, dim * win_len))\n",
        "\n",
        "    return X_tr, X_va, X_tst\n",
        "\n",
        "## Function to define CNN model.\n",
        "def model_CNN(dim, win_len, num_classes, num_feat_map=64, p=0., batchnorm=True, dropout=True):\n",
        "    model = Sequential(name='CNN')\n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 3),\n",
        "                     activation='relu',\n",
        "                     input_shape=(dim, win_len, 1),\n",
        "                     padding='same', name='Conv_1'))\n",
        "    if batchnorm:\n",
        "        model.add(BatchNormalization(name='Bn_1'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), name='Max_pool_1'))\n",
        "    if dropout:\n",
        "        model.add(Dropout(p, name='Drop_1'))\n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 3),\n",
        "                     activation='relu', padding='same', name='Conv_2'))\n",
        "    if batchnorm:\n",
        "        model.add(BatchNormalization(name='Bn_2'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), name='Max_pool_2'))\n",
        "    if dropout:\n",
        "        model.add(Dropout(p, name='Drop_2'))\n",
        "    model.add(Conv2D(num_feat_map, kernel_size=(1, 3),\n",
        "                     activation='relu', padding='same', name='Conv_3'))\n",
        "    if batchnorm:\n",
        "        model.add(BatchNormalization(name='Bn_3'))\n",
        "    model.add(MaxPooling2D(pool_size=(1, 2), name='Max_pool_3'))\n",
        "    if dropout:\n",
        "        model.add(Dropout(p, name='Drop_3'))\n",
        "    model.add(Flatten(name='Flatten_1'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    if batchnorm:\n",
        "        model.add(BatchNormalization(name='Bn_4'))\n",
        "    if dropout:\n",
        "        model.add(Dropout(p, name='Drop_4'))\n",
        "    model.add(Dense(num_classes, activation='softmax', name='dense_out'))\n",
        "    return model\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgTsD0dfl7m5"
      },
      "source": [
        "# Variables\n",
        "d_name        = 'WISDM_PAMAP2';\n",
        "network_type  = 'CNN';\n",
        "batch_size    = 256;\n",
        "epochs        = 50;\n",
        "model_dir     = f'Models/{d_name}';\n",
        "model_name    = '{}_{}'.format(network_type, int(time.time()));\n",
        "filepath      = f\"best_{model_name}.hdf5\";\n",
        "chk_path      = os.path.join(model_dir, filepath);\n",
        "\n",
        "ACTIVITIES_MAP = {\n",
        "    0: 'Walking',\n",
        "    1: 'Stairs',\n",
        "    2: 'Sitting',\n",
        "    3: 'Brushing Teeth',\n",
        "    4: 'Eating',\n",
        "    5: 'Jogging',\n",
        "    6: 'Clapping'\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLQJCfAg7Cv_"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfX7wcH7Cv_"
      },
      "source": [
        "Load the preprocessed data as stored in Numpy-files. Please note that the data has already been split up in a training (training), validation (val), and test subsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tovCMtHC7CwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3adce40-09b5-47d6-cf9c-49c9fa614cd8"
      },
      "source": [
        "# Load the dataset for training\n",
        "num_classes, sensors, locations, label_names, f_hz, dimensions, path = get_details(d_name)\n",
        "print(\"Number of classes:  \", num_classes)\n",
        "print(\"Sensors:            \", sensors)\n",
        "print(\"Devices:            \",locations)\n",
        "print(\"Sampling frequency: \",f_hz)\n",
        "\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "\n",
        "X_train0, y_train_binary, X_val0, y_val_binary, X_test0, y_test_binary = load_dataset(d_name, path, num_classes)\n",
        "print (\"Dataset Shapes:\")\n",
        "print(\"  Train inputs:      \",X_train0.shape);\n",
        "print(\"  Test inputs:       \",X_test0.shape);\n",
        "print(\"  Validation inputs: \",X_val0.shape);\n",
        "print(\"  Train labels:      \", y_train_binary.shape);\n",
        "print(\"  Test labels:       \",y_test_binary.shape);\n",
        "print(\"  Validation labels: \",y_val_binary.shape);\n",
        "\n",
        "np.load = np_load_old\n",
        "\n",
        "# Counting data for different activities\n",
        "y_train = np.argmax(y_train_binary, axis=1)\n",
        "y_test = np.argmax(y_test_binary, axis=1)\n",
        "y_val = np.argmax(y_val_binary, axis=1)\n",
        "\n",
        "print (\"Amount of data for each activity: \");\n",
        "train_count = Counter(y_train);\n",
        "print(\" Training Data:\");\n",
        "for activity in ACTIVITIES_MAP.keys():\n",
        "  print (\"    {} = {}\".format(ACTIVITIES_MAP[activity], train_count[activity]));\n",
        "val_count = Counter(y_val);\n",
        "print(\" Validation Data:\");\n",
        "for activity in ACTIVITIES_MAP.keys():\n",
        "  print (\"    {} = {}\".format(ACTIVITIES_MAP[activity], val_count[activity]));\n",
        "test_count = Counter(y_test);\n",
        "print(\" Testing Data:\");\n",
        "for activity in ACTIVITIES_MAP.keys():\n",
        "  print (\"    {} = {}\".format(ACTIVITIES_MAP[activity], test_count[activity]));   \n",
        "\n",
        "# Converting all the data to float32.\n",
        "X_train0        = np.asarray(X_train0).astype('float32')\n",
        "X_test0         = np.asarray(X_test0).astype('float32')\n",
        "X_val0          = np.asarray(X_val0).astype('float32')\n",
        "y_train_binary  = np.asarray(y_train_binary).astype('float32')\n",
        "y_test_binary   = np.asarray(y_test_binary).astype('float32')\n",
        "y_val_binary    = np.asarray(y_val_binary).astype('float32')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of classes:   7\n",
            "Sensors:             ['Accelerometer', 'Gyroscope']\n",
            "Devices:             ['Wrist Watch']\n",
            "Sampling frequency:  20\n",
            "Dataset Shapes:\n",
            "  Train inputs:       (31045, 202, 6)\n",
            "  Test inputs:        (6469, 202, 6)\n",
            "  Validation inputs:  (4151, 202, 6)\n",
            "  Train labels:       (31045, 7)\n",
            "  Test labels:        (6469, 7)\n",
            "  Validation labels:  (4151, 7)\n",
            "Amount of data for each activity: \n",
            " Training Data:\n",
            "    Walking = 4095\n",
            "    Stairs = 3278\n",
            "    Sitting = 7252\n",
            "    Brushing Teeth = 3279\n",
            "    Eating = 6671\n",
            "    Jogging = 3191\n",
            "    Clapping = 3279\n",
            " Validation Data:\n",
            "    Walking = 582\n",
            "    Stairs = 362\n",
            "    Sitting = 917\n",
            "    Brushing Teeth = 474\n",
            "    Eating = 911\n",
            "    Jogging = 438\n",
            "    Clapping = 467\n",
            " Testing Data:\n",
            "    Walking = 841\n",
            "    Stairs = 737\n",
            "    Sitting = 1465\n",
            "    Brushing Teeth = 682\n",
            "    Eating = 1364\n",
            "    Jogging = 698\n",
            "    Clapping = 682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmrbY32o7CwH"
      },
      "source": [
        "## My Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MBfizq6l7CwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dead8a7-b3be-4772-9106-81f32e85907d"
      },
      "source": [
        "print('Reshaping data for different models ...')\n",
        "X_train, X_val, X_test = reshape_data(X_train0, X_val0, X_test0, network_type)\n",
        "_, win_len, dim = X_train0.shape\n",
        "\n",
        "print('Building the model ...')\n",
        "model = model_CNN(dim, win_len, num_classes, num_feat_map=64, p=0.3)\n",
        "print(model.summary())\n",
        "\n",
        "print('Training the model ...')\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir = os.path.join('logs', '{}'.format(model_name)))\n",
        "\n",
        "checkpoint = ModelCheckpoint(chk_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit(X_train, y_train_binary,\n",
        "          batch_size=300,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          shuffle=True,\n",
        "          validation_data=(X_val, y_val_binary),\n",
        "          callbacks=[tensorboard, checkpoint])\n",
        "\n",
        "model.save(os.path.join(model_dir,f'final_{model_name}.hdf5'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reshaping data for different models ...\n",
            "Building the model ...\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv_1 (Conv2D)              (None, 6, 202, 64)        256       \n",
            "_________________________________________________________________\n",
            "Bn_1 (BatchNormalization)    (None, 6, 202, 64)        256       \n",
            "_________________________________________________________________\n",
            "Max_pool_1 (MaxPooling2D)    (None, 6, 101, 64)        0         \n",
            "_________________________________________________________________\n",
            "Drop_1 (Dropout)             (None, 6, 101, 64)        0         \n",
            "_________________________________________________________________\n",
            "Conv_2 (Conv2D)              (None, 6, 101, 64)        12352     \n",
            "_________________________________________________________________\n",
            "Bn_2 (BatchNormalization)    (None, 6, 101, 64)        256       \n",
            "_________________________________________________________________\n",
            "Max_pool_2 (MaxPooling2D)    (None, 6, 50, 64)         0         \n",
            "_________________________________________________________________\n",
            "Drop_2 (Dropout)             (None, 6, 50, 64)         0         \n",
            "_________________________________________________________________\n",
            "Conv_3 (Conv2D)              (None, 6, 50, 64)         12352     \n",
            "_________________________________________________________________\n",
            "Bn_3 (BatchNormalization)    (None, 6, 50, 64)         256       \n",
            "_________________________________________________________________\n",
            "Max_pool_3 (MaxPooling2D)    (None, 6, 25, 64)         0         \n",
            "_________________________________________________________________\n",
            "Drop_3 (Dropout)             (None, 6, 25, 64)         0         \n",
            "_________________________________________________________________\n",
            "Flatten_1 (Flatten)          (None, 9600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                307232    \n",
            "_________________________________________________________________\n",
            "Bn_4 (BatchNormalization)    (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "Drop_4 (Dropout)             (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_out (Dense)            (None, 7)                 231       \n",
            "=================================================================\n",
            "Total params: 333,319\n",
            "Trainable params: 332,871\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training the model ...\n",
            "Epoch 1/50\n",
            "  1/104 [..............................] - ETA: 0s - loss: 2.6566 - accuracy: 0.1433WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "  2/104 [..............................] - ETA: 6s - loss: 2.1276 - accuracy: 0.2917WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0228s vs `on_train_batch_end` time: 0.1114s). Check your callbacks.\n",
            "104/104 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.8045\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.30860, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 4s 43ms/step - loss: 0.5744 - accuracy: 0.8045 - val_loss: 1.9912 - val_accuracy: 0.3086\n",
            "Epoch 2/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.2964 - accuracy: 0.9054\n",
            "Epoch 00002: val_accuracy improved from 0.30860 to 0.41339, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.2959 - accuracy: 0.9055 - val_loss: 2.3574 - val_accuracy: 0.4134\n",
            "Epoch 3/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.2340 - accuracy: 0.9247\n",
            "Epoch 00003: val_accuracy improved from 0.41339 to 0.49482, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 3s 34ms/step - loss: 0.2341 - accuracy: 0.9246 - val_loss: 2.0768 - val_accuracy: 0.4948\n",
            "Epoch 4/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1879 - accuracy: 0.9387\n",
            "Epoch 00004: val_accuracy improved from 0.49482 to 0.58106, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.1877 - accuracy: 0.9387 - val_loss: 1.8156 - val_accuracy: 0.5811\n",
            "Epoch 5/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9477\n",
            "Epoch 00005: val_accuracy improved from 0.58106 to 0.69694, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.1622 - accuracy: 0.9478 - val_loss: 1.0279 - val_accuracy: 0.6969\n",
            "Epoch 6/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.9512\n",
            "Epoch 00006: val_accuracy did not improve from 0.69694\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.1473 - accuracy: 0.9512 - val_loss: 1.1110 - val_accuracy: 0.6936\n",
            "Epoch 7/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1266 - accuracy: 0.9592\n",
            "Epoch 00007: val_accuracy improved from 0.69694 to 0.73259, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.1265 - accuracy: 0.9593 - val_loss: 0.9577 - val_accuracy: 0.7326\n",
            "Epoch 8/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9631\n",
            "Epoch 00008: val_accuracy improved from 0.73259 to 0.78053, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 3s 34ms/step - loss: 0.1125 - accuracy: 0.9630 - val_loss: 0.9076 - val_accuracy: 0.7805\n",
            "Epoch 9/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.9660\n",
            "Epoch 00009: val_accuracy improved from 0.78053 to 0.79210, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.1017 - accuracy: 0.9661 - val_loss: 1.0618 - val_accuracy: 0.7921\n",
            "Epoch 10/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9690\n",
            "Epoch 00010: val_accuracy did not improve from 0.79210\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.0941 - accuracy: 0.9691 - val_loss: 1.0036 - val_accuracy: 0.7805\n",
            "Epoch 11/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9706\n",
            "Epoch 00011: val_accuracy did not improve from 0.79210\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.0906 - accuracy: 0.9704 - val_loss: 1.1053 - val_accuracy: 0.7798\n",
            "Epoch 12/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9720\n",
            "Epoch 00012: val_accuracy improved from 0.79210 to 0.79523, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 0.0822 - accuracy: 0.9721 - val_loss: 1.0899 - val_accuracy: 0.7952\n",
            "Epoch 13/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0786 - accuracy: 0.9740\n",
            "Epoch 00013: val_accuracy did not improve from 0.79523\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.0788 - accuracy: 0.9740 - val_loss: 1.1059 - val_accuracy: 0.7793\n",
            "Epoch 14/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 0.9770\n",
            "Epoch 00014: val_accuracy improved from 0.79523 to 0.80438, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0684 - accuracy: 0.9770 - val_loss: 1.1950 - val_accuracy: 0.8044\n",
            "Epoch 15/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9771\n",
            "Epoch 00015: val_accuracy improved from 0.80438 to 0.81041, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 1.2614 - val_accuracy: 0.8104\n",
            "Epoch 16/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 0.9791\n",
            "Epoch 00016: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.0620 - accuracy: 0.9790 - val_loss: 1.3469 - val_accuracy: 0.7817\n",
            "Epoch 17/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.9796\n",
            "Epoch 00017: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0605 - accuracy: 0.9796 - val_loss: 1.3531 - val_accuracy: 0.7890\n",
            "Epoch 18/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9797\n",
            "Epoch 00018: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.0585 - accuracy: 0.9796 - val_loss: 1.2842 - val_accuracy: 0.7967\n",
            "Epoch 19/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.9811\n",
            "Epoch 00019: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.0574 - accuracy: 0.9810 - val_loss: 1.3938 - val_accuracy: 0.7760\n",
            "Epoch 20/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9825\n",
            "Epoch 00020: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 3s 34ms/step - loss: 0.0519 - accuracy: 0.9826 - val_loss: 1.3192 - val_accuracy: 0.7938\n",
            "Epoch 21/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9825\n",
            "Epoch 00021: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 1.3220 - val_accuracy: 0.8020\n",
            "Epoch 22/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9831\n",
            "Epoch 00022: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0485 - accuracy: 0.9832 - val_loss: 1.3430 - val_accuracy: 0.8068\n",
            "Epoch 23/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9835\n",
            "Epoch 00023: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0477 - accuracy: 0.9834 - val_loss: 1.4983 - val_accuracy: 0.7957\n",
            "Epoch 24/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9844\n",
            "Epoch 00024: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0448 - accuracy: 0.9844 - val_loss: 1.5285 - val_accuracy: 0.7926\n",
            "Epoch 25/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9856\n",
            "Epoch 00025: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0439 - accuracy: 0.9855 - val_loss: 1.5778 - val_accuracy: 0.7813\n",
            "Epoch 26/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9857\n",
            "Epoch 00026: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 1.5690 - val_accuracy: 0.7827\n",
            "Epoch 27/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9859\n",
            "Epoch 00027: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0402 - accuracy: 0.9859 - val_loss: 1.3531 - val_accuracy: 0.7981\n",
            "Epoch 28/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0421 - accuracy: 0.9856\n",
            "Epoch 00028: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 1.4360 - val_accuracy: 0.7907\n",
            "Epoch 29/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9877\n",
            "Epoch 00029: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 1.6904 - val_accuracy: 0.7993\n",
            "Epoch 30/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9866\n",
            "Epoch 00030: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 1.5874 - val_accuracy: 0.7776\n",
            "Epoch 31/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9875\n",
            "Epoch 00031: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0380 - accuracy: 0.9875 - val_loss: 1.4440 - val_accuracy: 0.8075\n",
            "Epoch 32/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9866\n",
            "Epoch 00032: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0390 - accuracy: 0.9865 - val_loss: 1.5370 - val_accuracy: 0.7933\n",
            "Epoch 33/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9860\n",
            "Epoch 00033: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 1.7433 - val_accuracy: 0.7870\n",
            "Epoch 34/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9878\n",
            "Epoch 00034: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0352 - accuracy: 0.9879 - val_loss: 1.5766 - val_accuracy: 0.7947\n",
            "Epoch 35/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9875\n",
            "Epoch 00035: val_accuracy did not improve from 0.81041\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0361 - accuracy: 0.9875 - val_loss: 1.4628 - val_accuracy: 0.7928\n",
            "Epoch 36/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9887\n",
            "Epoch 00036: val_accuracy improved from 0.81041 to 0.81498, saving model to Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 0.0319 - accuracy: 0.9886 - val_loss: 1.4842 - val_accuracy: 0.8150\n",
            "Epoch 37/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9878\n",
            "Epoch 00037: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 1.6440 - val_accuracy: 0.7972\n",
            "Epoch 38/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9897\n",
            "Epoch 00038: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 1.6355 - val_accuracy: 0.8027\n",
            "Epoch 39/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9895\n",
            "Epoch 00039: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 1.6175 - val_accuracy: 0.8058\n",
            "Epoch 40/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9906\n",
            "Epoch 00040: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 1.7438 - val_accuracy: 0.8027\n",
            "Epoch 41/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9903\n",
            "Epoch 00041: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 1.6703 - val_accuracy: 0.7757\n",
            "Epoch 42/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9908\n",
            "Epoch 00042: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 1.7805 - val_accuracy: 0.8058\n",
            "Epoch 43/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9903\n",
            "Epoch 00043: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0275 - accuracy: 0.9903 - val_loss: 1.4643 - val_accuracy: 0.8003\n",
            "Epoch 44/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9904\n",
            "Epoch 00044: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0273 - accuracy: 0.9904 - val_loss: 1.5953 - val_accuracy: 0.8082\n",
            "Epoch 45/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9899\n",
            "Epoch 00045: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 1.7904 - val_accuracy: 0.7931\n",
            "Epoch 46/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9921\n",
            "Epoch 00046: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 1.7781 - val_accuracy: 0.7776\n",
            "Epoch 47/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9907\n",
            "Epoch 00047: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 1.6045 - val_accuracy: 0.7979\n",
            "Epoch 48/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9921\n",
            "Epoch 00048: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 1.8045 - val_accuracy: 0.7950\n",
            "Epoch 49/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9907\n",
            "Epoch 00049: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 1.7884 - val_accuracy: 0.7822\n",
            "Epoch 50/50\n",
            "103/104 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9924\n",
            "Epoch 00050: val_accuracy did not improve from 0.81498\n",
            "104/104 [==============================] - 4s 34ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 1.7649 - val_accuracy: 0.7861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHzUiWAP7CwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9453a33-ac08-4054-e7da-5401d6acc1bf"
      },
      "source": [
        "## Reloading saved model\n",
        "print(\"Loading the model: {}\".format(chk_path));\n",
        "model = load_model(chk_path);"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the model: Models/WISDM_PAMAP2/best_CNN_1607829123.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SghxinCU7CwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8139d447-732f-4fa7-8429-70b17dc53547"
      },
      "source": [
        "## Testing the trained model accuracy with test data set.\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test_binary, axis=1)\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix: \")\n",
        "print(cf_matrix)\n",
        "class_wise_f1 = f1_score(y_true, y_pred, average=None)\n",
        "print('The mean-f1 score: {:.4f}'.format(np.mean(class_wise_f1)))\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print('Accuracy is: {:.4f}'.format(accuracy))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            "[[ 670  113   24   17   11    3    3]\n",
            " [  79  594    8    3   45    6    2]\n",
            " [   0    0 1331    1  130    0    3]\n",
            " [   0    0    0  668   14    0    0]\n",
            " [   2    0  186    9 1157    0   10]\n",
            " [   7    7    0    1    2  681    0]\n",
            " [   0    0    0    1    0    0  681]]\n",
            "The mean-f1 score: 0.9034\n",
            "Accuracy is: 0.8938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6vIt869s9h4"
      },
      "source": [
        "Perform Inference on live data collected from Apple Watch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boWa5B_c2FCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50b071a-0a4a-406b-96d6-ef0f433de2cf"
      },
      "source": [
        "# Live data collected from Apple Watch\n",
        "file_list = [\n",
        "  '2020_11_22_Rahul_0_1', '2020_11_22_Mohit_0_1',\n",
        "  '2020_11_22_Mohit_2_1',\n",
        "  '2020_11_22_Rahul_3', '2020_11_21_Rahul_3', '2020_11_23_Rahul_3', '2020_11_24_Rahul_3', '2020_11_26_Rahul_3', '2020_11_29_Mohit_3',\n",
        "  '2020_11_20_Rahul_4', '2020_11_29_Mohit_4',\n",
        "  '2020_11_22_Rahul_1_1', '2020_11_22_Mohit_1_1', '2020_11_22_Rahul_1_2', '2020_11_22_Mohit_1_2',\n",
        "  '2020_12_04_Mohit_up_1', '2020_12_04_Mohit_down_1', '2020_12_04_Rahul_up_1', '2020_12_04_Rahul_down_1',\n",
        "  '2020_12_04_Mohit_5',\n",
        "  '2020_11_30_Rahul_5'\n",
        "];\n",
        "exp_activities = [0,0,2,3,3,3,3,3,3,4,4,1,1,1,1,1,1,1,1,5,6];\n",
        "\n",
        "for (file_name,exp_act) in zip(file_list,exp_activities):\n",
        "  X_data0 = np.load('./Data/Live_Data/processed/X_'+file_name+'.npy')\n",
        "  Y_true = np.load('./Data/Live_Data/processed/Y_'+file_name+'.npy')\n",
        "\n",
        "  X_data, a, b = reshape_data(X_data0, X_data0, X_data0, network_type)\n",
        "  Y_pred = np.argmax(model.predict(X_data), axis=1)\n",
        "  cf_matrix = confusion_matrix(Y_true, Y_pred)\n",
        "  class_wise_f1 = f1_score(Y_true, Y_pred, average=None)\n",
        "  accuracy = accuracy_score(Y_true, Y_pred)\n",
        "  counts = np.bincount(Y_pred)\n",
        "  activity_id = np.argmax(counts)\n",
        "  print(\"===========================================================\");\n",
        "  if os.path.exists('./Data/Live_Data/processed/'+file_name+'_dt.csv'):\n",
        "    dt = pd.read_csv('./Data/Live_Data/processed/'+file_name+'_dt.csv');\n",
        "    print (\"Activity Start Time: \" + str(dt.iloc[0,1]) + ' ' +str(dt.iloc[0,2]) );\n",
        "    print (\"Activity End Time:   \" + str(dt.iloc[1,1]) + ' ' +str(dt.iloc[1,2]) );\n",
        "  print('Accuracy:            {:.4f}'.format(accuracy))\n",
        "  print(\"Expected Activity:   {}\".format(ACTIVITIES_MAP[exp_act]));    \n",
        "  print(\"Detected Activity:   {}\".format(ACTIVITIES_MAP[activity_id]));\n",
        "  print(\"===========================================================\");"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 10:49:11.637\n",
            "Activity End Time:   2020-11-22 10:59:22.238\n",
            "Accuracy:            0.9668\n",
            "Expected Activity:   Walking\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 11:25:36.540\n",
            "Activity End Time:   2020-11-22 11:32:01.269\n",
            "Accuracy:            0.5532\n",
            "Expected Activity:   Walking\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 12:25:24.437\n",
            "Activity End Time:   2020-11-22 12:27:07.375\n",
            "Accuracy:            0.9362\n",
            "Expected Activity:   Sitting\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 09:37:32.630\n",
            "Activity End Time:   2020-11-22 09:40:18.282\n",
            "Accuracy:            0.9872\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Accuracy:            1.0000\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-23 08:25:43.287\n",
            "Activity End Time:   2020-11-23 08:28:32.150\n",
            "Accuracy:            0.9875\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-24 09:28:23.732\n",
            "Activity End Time:   2020-11-24 09:30:49.135\n",
            "Accuracy:            0.9559\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-26 09:49:01.224\n",
            "Activity End Time:   2020-11-26 09:51:51.980\n",
            "Accuracy:            0.9877\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-29 18:37:20.689\n",
            "Activity End Time:   2020-11-29 18:39:38.849\n",
            "Accuracy:            0.9692\n",
            "Expected Activity:   Brushing Teeth\n",
            "Detected Activity:   Brushing Teeth\n",
            "===========================================================\n",
            "===========================================================\n",
            "Accuracy:            0.7143\n",
            "Expected Activity:   Eating\n",
            "Detected Activity:   Eating\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-29 18:45:56.215\n",
            "Activity End Time:   2020-11-29 18:50:37.730\n",
            "Accuracy:            0.7132\n",
            "Expected Activity:   Eating\n",
            "Detected Activity:   Eating\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 11:45:00.744\n",
            "Activity End Time:   2020-11-22 11:47:35.607\n",
            "Accuracy:            0.0137\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 11:37:34.255\n",
            "Activity End Time:   2020-11-22 11:39:50.607\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 12:17:08.319\n",
            "Activity End Time:   2020-11-22 12:19:44.195\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-11-22 12:08:08.875\n",
            "Activity End Time:   2020-11-22 12:10:19.313\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Walking\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:32:44.320\n",
            "Activity End Time:   2020-12-04 12:33:35.324\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:34:03.442\n",
            "Activity End Time:   2020-12-04 12:34:48.766\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:35:23.692\n",
            "Activity End Time:   2020-12-04 12:36:28.972\n",
            "Accuracy:            0.1071\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:36:33.574\n",
            "Activity End Time:   2020-12-04 12:37:32.956\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Stairs\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Activity Start Time: 2020-12-04 12:36:33.574\n",
            "Activity End Time:   2020-12-04 12:37:32.956\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Jogging\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n",
            "===========================================================\n",
            "Accuracy:            0.0000\n",
            "Expected Activity:   Clapping\n",
            "Detected Activity:   Sitting\n",
            "===========================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A88qTryjyNTU"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}