{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocess_PAMAP2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmzy8LkaOv65",
        "outputId": "63869f15-5540-4604-c4da-4d39d89459ff"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsSlyyu-O7JQ",
        "outputId": "275e930b-024b-43ec-ce53-c6b3d96d9bd0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQwOmUqZO-33",
        "outputId": "4375f1dd-c147-4f47-a4a6-9a1ffcd14d3c"
      },
      "source": [
        "cd '/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG/Data/PAMAP2'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/Rahul_Mohit/ECE202A/WALG/Data/PAMAP2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1mNQc7pPIeS"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import listdir\n",
        "import os.path\n",
        "import zipfile\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import json"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh6IBBABPcDH"
      },
      "source": [
        "## Function to split activities\n",
        "def split_activities(labels, X, exclude_activities, borders=10 * 100):\n",
        "    tot_len = len(labels)\n",
        "    startpoints = np.where([1] + [labels[i] != labels[i - 1]\n",
        "                                  for i in range(1, tot_len)])[0]\n",
        "    endpoints = np.append(startpoints[1:] - 1, tot_len - 1)\n",
        "    acts = [labels[s] for s, e in zip(startpoints, endpoints)]\n",
        "    # Also split up the data, and only keep the non-zero activities\n",
        "    xysplit = [(X[s + borders:e - borders + 1, :], a)\n",
        "               for s, e, a in zip(startpoints, endpoints, acts)\n",
        "               if a not in exclude_activities and e-borders+1>=0 and s+borders<tot_len]\n",
        "    xysplit = [(Xs, y) for Xs, y in xysplit if len(Xs) > 0]\n",
        "    Xlist = [Xs for Xs, y in xysplit]\n",
        "    ylist = [y for X, y in xysplit]\n",
        "    return Xlist, ylist\n",
        "\n",
        "## Function to split data into windows\n",
        "def sliding_window(frame_length, step, Xsampleslist, ysampleslist):\n",
        "    Xsamples = []\n",
        "    ysamples = []\n",
        "    for j in range(len(Xsampleslist)):\n",
        "        X = Xsampleslist[j]\n",
        "        ybinary = ysampleslist[j]\n",
        "        for i in range(0, X.shape[0] - frame_length, step):\n",
        "            xsub = [];\n",
        "            for k in range(0,frame_length,5):\n",
        "                xsub.append(X[i+k,:]);\n",
        "            xsub.append(np.mean(xsub[0:200],axis=0));\n",
        "            xsub.append(np.std(xsub[0:200],axis=0,dtype=np.float64))\n",
        "            #xsub = X[i:i + frame_length, :]\n",
        "            ysub = ybinary\n",
        "            Xsamples.append(xsub)\n",
        "            ysamples.append(ysub)\n",
        "    return Xsamples, ysamples\n",
        "\n",
        "## Function to transform labels\n",
        "def transform_y(y, mapclasses, nr_classes):\n",
        "    ymapped = np.array([mapclasses[c] for c in y], dtype='int')\n",
        "    ybinary = to_categorical(ymapped, nr_classes)\n",
        "    return ybinary\n",
        "\n",
        "## Function to get headers\n",
        "def get_header():\n",
        "    axes = ['x', 'y', 'z']\n",
        "    IMUsensor_columns = ['temperature'] + \\\n",
        "        ['acc_16g_' + i for i in axes] + \\\n",
        "        ['acc_6g_' + i for i in axes] + \\\n",
        "        ['gyroscope_' + i for i in axes] + \\\n",
        "        ['magnometer_' + i for i in axes] + \\\n",
        "        ['orientation_' + str(i) for i in range(4)]\n",
        "    header = [\"timestamp\", \"activityID\", \"heartrate\"] + [\"hand_\" + s for s in IMUsensor_columns] \\\n",
        "        + [\"chest_\" + s for s in IMUsensor_columns] + [\"ankle_\" + s for s in IMUsensor_columns]\n",
        "    return header\n",
        "\n",
        "## Function to add header to the data\n",
        "def addheader(datasets):\n",
        "    header = get_header()\n",
        "    for i in range(0, len(datasets)):\n",
        "        datasets[i].columns = header\n",
        "    return datasets\n",
        "\n",
        "## Function to store data as numpy files.\n",
        "def numpify_and_store(X, y, X_name, y_name, outdatapath, shuffle=False):\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # Shuffle the train set\n",
        "    if shuffle is True:\n",
        "        np.random.seed(123)\n",
        "        neworder = np.random.permutation(X.shape[0])\n",
        "        X = X[neworder, :, :]\n",
        "        y = y[neworder, :]\n",
        "    # Save binary file\n",
        "    xpath = os.path.join(outdatapath, X_name)\n",
        "    ypath = os.path.join(outdatapath, y_name)\n",
        "    np.save(xpath, X)\n",
        "    np.save(ypath, y)\n",
        "    print('Storing ' + xpath, ypath)\n",
        "\n",
        "## Function to map classes.\n",
        "def map_class(datasets_filled, exclude_activities):\n",
        "    ysetall = [set(np.array(data.activityID)) - set(exclude_activities)\n",
        "               for data in datasets_filled]\n",
        "    class_ids = list(set.union(*[set(y) for y in ysetall]))\n",
        "    class_labels = [ACTIVITIES_MAP[i] for i in class_ids]\n",
        "    for i in class_ids:\n",
        "      print(ACTIVITIES_MAP[i])\n",
        "    nr_classes = len(class_ids)\n",
        "    mapclasses = {class_ids[i]: i for i in range(len(class_ids))}\n",
        "    return class_labels, nr_classes, mapclasses\n",
        "\n",
        "## Function to split data.\n",
        "def split_data(Xlists, ybinarylists, indices):\n",
        "    tty = str(type(indices))\n",
        "    if tty == \"<class 'slice'>\" or tty == \"<type 'slice'>\":\n",
        "        x_setlist = [X for Xlist in Xlists[indices] for X in Xlist]\n",
        "        y_setlist = [y for ylist in ybinarylists[indices] for y in ylist]\n",
        "    else:\n",
        "        x_setlist = [X for X in Xlists[indices]]\n",
        "        y_setlist = [y for y in ybinarylists[indices]]\n",
        "    return x_setlist, y_setlist"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc3WHIOnQZEL"
      },
      "source": [
        "## Variables\n",
        "frame_length = int(1000);\n",
        "step         = 200;\n",
        "datadir = os.path.join('..', 'PAMAP2_Dataset', 'Protocol');\n",
        "columns_to_use = ['hand_acc_16g_x', 'hand_acc_16g_y', 'hand_acc_16g_z',\n",
        "                  'hand_gyroscope_x', 'hand_gyroscope_y', 'hand_gyroscope_z', \n",
        "                  'hand_magnometer_x', 'hand_magnometer_y', 'hand_magnometer_z',\n",
        "                  'ankle_acc_16g_x', 'ankle_acc_16g_y', 'ankle_acc_16g_z',\n",
        "                  'ankle_gyroscope_x', 'ankle_gyroscope_y', 'ankle_gyroscope_z',\n",
        "                  'ankle_magnometer_x', 'ankle_magnometer_y', 'ankle_magnometer_z',\n",
        "                  'chest_acc_16g_x', 'chest_acc_16g_y', 'chest_acc_16g_z',\n",
        "                  'chest_gyroscope_x', 'chest_gyroscope_y', 'chest_gyroscope_z',\n",
        "                  'chest_magnometer_x', 'chest_magnometer_y', 'chest_magnometer_z']\n",
        "\n",
        "ACTIVITIES_MAP = {\n",
        "    0: 'no_activity',\n",
        "    1: 'lying',\n",
        "    2: 'sitting',\n",
        "    3: 'standing',\n",
        "    4: 'walking',\n",
        "    5: 'running',\n",
        "    6: 'cycling',\n",
        "    7: 'nordic_walking',\n",
        "    9: 'watching_tv',\n",
        "    10: 'computer_work',\n",
        "    11: 'car_driving',\n",
        "    12: 'ascending_stairs',\n",
        "    13: 'descending_stairs',\n",
        "    16: 'vaccuum_cleaning',\n",
        "    17: 'ironing',\n",
        "    18: 'folding_laundry',\n",
        "    19: 'house_cleaning',\n",
        "    20: 'playing_soccer',\n",
        "    24: 'rope_jumping'\n",
        "};"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPYr0j4XX6m1",
        "outputId": "6581a4f2-6d74-4d75-fdd3-4c8e17170897"
      },
      "source": [
        "filenames = os.listdir(datadir)\n",
        "filenames.sort()\n",
        "print('Start pre-processing all ' + str(len(filenames)) + ' files...')\n",
        "# Load the files and put them in a list of pandas dataframes:\n",
        "datasets = [pd.read_csv(os.path.join(datadir, fn), header=None, sep=' ') for fn in filenames]\n",
        "datasets = addheader(datasets)  # add headers to the datasets\n",
        "# Interpolate dataset to get same sample rate between channels\n",
        "datasets_filled = [d.interpolate() for d in datasets]\n",
        "print('loaded the dataset')\n",
        "class_labels, nr_classes, mapclasses = map_class(datasets_filled, exclude_activities=[0])\n",
        "\n",
        "# Create input (x) and output (y) sets\n",
        "xall = [np.array(data[columns_to_use]) for data in datasets_filled]\n",
        "yall = [np.array(data.activityID) for data in datasets_filled]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start pre-processing all 9 files...\n",
            "loaded the dataset\n",
            "lying\n",
            "sitting\n",
            "standing\n",
            "walking\n",
            "running\n",
            "cycling\n",
            "nordic_walking\n",
            "ascending_stairs\n",
            "descending_stairs\n",
            "vaccuum_cleaning\n",
            "ironing\n",
            "rope_jumping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3A4pplNR7xH",
        "outputId": "1c5301f4-8009-4f18-caf9-1b44a30720b3"
      },
      "source": [
        "for activity in [2, 4]:\n",
        "  exclude_activities = list(ACTIVITIES_MAP.keys()-[activity]);\n",
        "  outdatapath = ACTIVITIES_MAP[activity];\n",
        "  if not os.path.exists(outdatapath):\n",
        "    os.mkdir(outdatapath);\n",
        "\n",
        "  xylists = [split_activities(y, x, exclude_activities) for x, y in zip(xall, yall)];\n",
        "  Xlists, ylists = zip(*xylists);\n",
        "  ybinarylists = [transform_y(y, mapclasses, nr_classes) for y in ylists];\n",
        "\n",
        "  # Split in train, test and val\n",
        "  train_range_1 = slice(0, 4);\n",
        "  train_range_2 = slice(6, len(datasets_filled));\n",
        "  x_vallist, y_vallist         = split_data(Xlists, ybinarylists, indices=4);\n",
        "  x_testlist, y_testlist       = split_data(Xlists, ybinarylists, indices=5);\n",
        "  x_trainlist_1, y_trainlist_1 = split_data(Xlists, ybinarylists, indices=train_range_1);\n",
        "  x_trainlist_2, y_trainlist_2 = split_data(Xlists, ybinarylists, indices=train_range_2);\n",
        "\n",
        "  # Take sliding-window frames, target is label of last time step, and store as numpy file\n",
        "  x_train_1, y_train_1 = sliding_window(frame_length, step, x_trainlist_1, y_trainlist_1);\n",
        "  x_train_2, y_train_2 = sliding_window(frame_length, step, x_trainlist_2, y_trainlist_2);\n",
        "  x_train = x_train_1 + x_train_2;\n",
        "  y_train = y_train_1 + y_train_2;\n",
        "\n",
        "  x_val, y_val   = sliding_window(frame_length, step, x_vallist, y_vallist);\n",
        "  x_test, y_test = sliding_window(frame_length, step, x_testlist, y_testlist);\n",
        "\n",
        "  numpify_and_store(\n",
        "    x_train, \n",
        "    y_train, \n",
        "    X_name='X_PAMAP2_train', \n",
        "    y_name='y_PAMAP2_train',\n",
        "    outdatapath=outdatapath, \n",
        "    shuffle=True\n",
        "  );\n",
        "  numpify_and_store(\n",
        "      x_val, \n",
        "      y_val, \n",
        "      X_name='X_PAMAP2_val', \n",
        "      y_name='y_PAMAP2_val',\n",
        "      outdatapath=outdatapath, \n",
        "      shuffle=False\n",
        "  );\n",
        "  numpify_and_store(\n",
        "      x_test, \n",
        "      y_test, \n",
        "      X_name='X_PAMAP2_test', \n",
        "      y_name='y_PAMAP2_test',\n",
        "      outdatapath=outdatapath, \n",
        "      shuffle=False\n",
        "  );\n",
        "\n",
        "  print('Processed data succesfully stored in ' + outdatapath)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Storing sitting/X_PAMAP2_train sitting/y_PAMAP2_train\n",
            "Storing sitting/X_PAMAP2_val sitting/y_PAMAP2_val\n",
            "Storing sitting/X_PAMAP2_test sitting/y_PAMAP2_test\n",
            "Processed data succesfully stored in sitting\n",
            "Storing walking/X_PAMAP2_train walking/y_PAMAP2_train\n",
            "Storing walking/X_PAMAP2_val walking/y_PAMAP2_val\n",
            "Storing walking/X_PAMAP2_test walking/y_PAMAP2_test\n",
            "Processed data succesfully stored in walking\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}